#!/bin/bash

# Ollama startup script

echo "ğŸš€ Starting Ollama..."

# Check if Ollama is already running
if pgrep -f "ollama serve" > /dev/null; then
    echo "âœ… Ollama is already running"
    echo "ğŸ“ Server: http://127.0.0.1:11434"
    exit 0
fi

# Start Ollama server in background
echo "ğŸ”„ Starting Ollama server..."
nohup ollama serve > /tmp/ollama.log 2>&1 &

# Wait for server to start
echo "â³ Waiting for server to start..."
sleep 3

# Check if server is responding
if curl -s http://127.0.0.1:11434 > /dev/null; then
    echo "âœ… Ollama server started successfully"
    echo "ğŸ“ Server: http://127.0.0.1:11434"
    echo "ğŸ“ Logs: /tmp/ollama.log"
    echo ""
    echo "Available commands:"
    echo "  ollama pull <model>    # Download a model"
    echo "  ollama run <model>     # Run a model"
    echo "  ollama list            # List installed models"
else
    echo "âŒ Failed to start Ollama server"
    echo "ğŸ“ Check logs: /tmp/ollama.log"
    exit 1
fi